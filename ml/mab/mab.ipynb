{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def argmax(a, f):\n",
    "  max_i = 0\n",
    "  max_v = a[0]\n",
    "  for i in range(len(a)):\n",
    "    v = f(i)\n",
    "    if max_v < v:\n",
    "      max_v = v\n",
    "      max_i = i\n",
    "  return max_i\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from random import random\n",
    "from random import randrange\n",
    "\n",
    "class Policy(object):\n",
    "  def choose(self, step: int, value_estimates: List, action_attempts: List) -> int:\n",
    "    return randrange(len(value_estimates))\n",
    "\n",
    "  def __str__(self) -> str:\n",
    "    return \"Random\"\n",
    "\n",
    "\n",
    "class GreedyPolicy(Policy):\n",
    "  def __init__(self):\n",
    "    pass\n",
    "\n",
    "  def choose(self, step: int, value_estimates: List, action_attempts: List) -> int:\n",
    "    return argmax(value_estimates, lambda i: value_estimates[i])\n",
    "\n",
    "  def __str__(self) -> str:\n",
    "    return \"Greedy\"\n",
    "\n",
    "\n",
    "class EpsilonGreedyPolicy(Policy):\n",
    "  def __init__(self, e: float):\n",
    "    self.e = e\n",
    "\n",
    "  def choose(self, step: int, value_estimates: List, action_attempts: List) -> int:\n",
    "    if random() < self.e:\n",
    "      return randrange(len(value_estimates))\n",
    "\n",
    "    return argmax(value_estimates, lambda i: value_estimates[i])\n",
    "\n",
    "  def __str__(self) -> str:\n",
    "    return \"EpsilonGreedy-{}\".format(self.e)\n",
    "\n",
    "def ucb_selection(value_estimates: List, action_attempts: List, i: int, c: float, step: int):\n",
    "  if action_attempts[i] == 0:\n",
    "    return value_estimates[i]\n",
    "  return value_estimates[i] + math.pow(math.log(step) / action_attempts[i], 1/c)\n",
    "\n",
    "class UcbPolicy(Policy):\n",
    "  def __init__(self, e: float, c: float):\n",
    "    self.e = e\n",
    "    self.c = c\n",
    "\n",
    "  def choose(self, step: int, value_estimates: List, action_attempts: List) -> int:\n",
    "    if random() < self.e:\n",
    "      if step == 0:\n",
    "        return randrange(len(value_estimates))\n",
    "      return argmax(action_attempts, lambda i: ucb_selection(value_estimates, action_attempts, i, self.c, step))\n",
    "\n",
    "    return argmax(value_estimates, lambda i: value_estimates[i])\n",
    "\n",
    "  def __str__(self) -> str:\n",
    "    return \"UCB-{}-{}\".format(self.e, self.c)\n",
    "\n",
    "\n",
    "class Agent:\n",
    "  def __init__(self, k: int, policy: Policy):\n",
    "    self.policy = policy\n",
    "    self.value_estimates = []\n",
    "    self.action_attempts = []\n",
    "    self.last_action = -1\n",
    "\n",
    "    for i in range(k):\n",
    "      self.value_estimates.append(0)\n",
    "      self.action_attempts.append(0)\n",
    "\n",
    "  def choose(self, step: int) -> int:\n",
    "    self.last_action = self.policy.choose(\n",
    "      step, self.value_estimates, self.action_attempts)\n",
    "    return self.last_action\n",
    "\n",
    "  def observe(self, reward: float):\n",
    "    self.action_attempts[self.last_action] += 1\n",
    "    regret = reward - self.value_estimates[self.last_action]\n",
    "    step_size = 1 / float(self.action_attempts[self.last_action])\n",
    "    self.value_estimates[self.last_action] += regret * step_size\n",
    "\n",
    "\n",
    "class GaussianBandit:\n",
    "  def __init__(self, mean: float, variance: float, k: int):\n",
    "    self.arms = np.random.normal(mean, variance, k)\n",
    "    self.variance = variance\n",
    "\n",
    "  def pull(self, arm: int) -> float:\n",
    "    return np.random.normal(self.arms[arm], self.variance)\n",
    "\n",
    "  def __str__(self):\n",
    "    return \"{}\".format(self.arms)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bandit = GaussianBandit(0, 1, 10)\n",
    "print(bandit)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "policies = [\n",
    "  Policy(),\n",
    "  GreedyPolicy(),\n",
    "  EpsilonGreedyPolicy(0.2),\n",
    "  EpsilonGreedyPolicy(0.1),\n",
    "  EpsilonGreedyPolicy(0.01),\n",
    "  UcbPolicy(0.01, 2),\n",
    "]\n",
    "\n",
    "agents = [Agent(len(bandit.arms), p) for p in policies]\n",
    "\n",
    "global_total_rewards = []\n",
    "global_avg_rewards = []\n",
    "for n in range(1, 1100):\n",
    "  total_rewards = []\n",
    "  avg_rewards = []\n",
    "  for _ in range(len(agents)):\n",
    "    total_rewards.append(0)\n",
    "    avg_rewards.append(0)\n",
    "\n",
    "  for step in range(n):\n",
    "    for i, agent in enumerate(agents):\n",
    "      arm = agent.choose(step)\n",
    "      reward = bandit.pull(arm)\n",
    "      total_rewards[i] += reward\n",
    "      avg_rewards[i] = (avg_rewards[i] * step + reward) / (step + 1)\n",
    "      agent.observe(reward)\n",
    "\n",
    "  global_total_rewards.append(total_rewards)\n",
    "  global_avg_rewards.append(avg_rewards)\n",
    "\n",
    "policy_names = [str(p) for p in policies]\n",
    "total_rewards_df = pd.DataFrame(data=global_total_rewards, columns=policy_names)\n",
    "avg_rewards_df = pd.DataFrame(data=global_avg_rewards, columns=policy_names)\n",
    "\n",
    "display(total_rewards_df)\n",
    "display(avg_rewards_df)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "px.line(total_rewards_df, labels={\"index\": \"Steps\", \"value\": \"Total Reward\"}).show()\n",
    "px.line(avg_rewards_df, labels={\"index\": \"Steps\", \"value\": \"Average Reward\"}).show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
